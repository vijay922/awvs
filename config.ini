[awvs_url_key]#基本设置
awvs_url=https://127.0.0.1:13443/
api_key=1769fc42b07ff46c2a126761c210c63cbfd832df3221848f388e23b50a86a4b5a

#待扫描的url文件
domain_file=url.txt

##扫描速度，由慢到快:sequential slow moderate fast， 速度越快，遗漏越多，则之相反
[scan_seting]
scan_speed=moderate

#扫描时的Cookie，对所有url生效， 如不添加Cookie，请保持为空，即扫描器爬虫自动获取，对所有url全局生效
#例子cookie=BIDUPSID=D40B5A304EFD449C3F8DED17FDF633A0; PSTM=1592016294
cookie=

#支持1个或多个自定义请求头，对所有url全局生效
#例子custom_headers=["x-auth: 2986ad8c0a5b3","Referer: https://192.168.163.139:13443/"]
custom_headers=[]

#排除不扫描的目录，通常用于在于添加cookie后，不执行退出，注销等操作，对所有url全局生效
#例子excluded_paths=['quit','exit','logout','Logout','delete','DELETE','注销','退出','删除']
excluded_paths=[]


##将抓取限制为仅包含地址和子目录 值:true(默认)/False，建议False更好
limit_crawler_scope=False

##配置上级代理地址，如联动被动扫描器，目标调试等，对所有url全局生效、
#例子proxy_server=127.0.0.1:7777  不要带http,没有请保持空， proxy_enabled=False\True, 注意大小写
proxy_enabled=False
proxy_server=127.0.0.1:8080


webhook_url=x
